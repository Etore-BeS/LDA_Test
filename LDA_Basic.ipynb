{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas necessárias\n",
    "import spacy\n",
    "import re\n",
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.decomposition import NMF\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/sentenças_educacao.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input de Docs com prompt\n",
    "Input dos docs em um modelo LLM com prompt dedicado a clusterizar os textos da melhor forma possível explicando cada tópico e dando output do número de tópicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be applied after due to cost of running an LLM locally\n",
    "\n",
    "# Will be assumed a that the LLM will output 8 clusters of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output do LLM será inserido aqui\n",
    "llm_guess = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - NLP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palavras personalizadas para remoção\n",
    "custom_words = {\n",
    "    \"alguns\", \"pouco\", \"muito\", \"toda\", \"todo\", \"algum\", \"certo\",\n",
    "    \"vários\", \"nenhum\", \"tanto\", \"quanto\", \"tudo\", \"nada\", \"exmo\",\n",
    "    \"provimento\", \"termos\", \"voto\", \"exmo\", \"relator\", \"juizes\", \"que\",\n",
    "    \"turma\", \"recursal\", \"jecs\", \"unanimidade\", \"conhecer\", \"recurso\",\n",
    "    \"nos\", \"termos\", \"do\", \"voto\", \"do\", \"exmo\", \"relator\", \"integram\",\n",
    "    'ilustre', 'dr', ''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo de linguagem Português\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "nlp.Defaults.stop_words |= custom_words  # Adicionando stopwords personalizadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(path)\n",
    "docs = df.iloc[:, 2].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches e TF-IDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_docs(docs, n):\n",
    "    \"\"\"\n",
    "    Separa os docs em n subcorpora.\n",
    "    \"\"\"\n",
    "    np.random.shuffle(docs)\n",
    "    tamanho_subcorpus = len(docs) // n\n",
    "    batches = [\n",
    "        docs[i * tamanho_subcorpus: (i + 1) * tamanho_subcorpus]\n",
    "        for i in range(n)\n",
    "    ]\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_docs = separar_docs(docs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar e preprocessar o corpus\n",
    "def preprocessar(docs, nlp):\n",
    "    def limpar_texto(texto):\n",
    "        texto = re.sub(r\"<.*?>\", \"\", texto)\n",
    "        texto = re.sub(r\"[^\\w\\s]\", \"\", texto)\n",
    "        texto = re.sub(r\"\\s+\", \" \", texto)\n",
    "        texto = re.sub(r\"[^\\x00-\\x7F]+\", \" \", texto)\n",
    "        texto = re.sub(r\"\\d[a|o]\", \"\", texto)\n",
    "        texto = re.sub(r'(\\w+?)(lhe|lhes)\\b', r'\\1', texto)\n",
    "        return texto\n",
    "\n",
    "    def preprocessar_texto(texto):\n",
    "        texto_limpo = limpar_texto(texto)\n",
    "        doc = nlp(texto_limpo)\n",
    "        tokens = [\n",
    "            token.lower_\n",
    "            for token in doc\n",
    "            if not token.is_stop \n",
    "            and not token.is_punct\n",
    "            and not token.like_num\n",
    "            ]\n",
    "        return tokens\n",
    "\n",
    "    corpus_preprocessado = [preprocessar_texto(doc) for doc in docs]\n",
    "    return corpus_preprocessado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['representante', 'membro', 'mat', 'julgamento', 'publico', 'ministerio', 'fazendaria', 'presente']]\n"
     ]
    }
   ],
   "source": [
    "print(preprocessar(\n",
    "        ['Ilustre representante membro mat dr julgamento publico ministerio fazendaria presente'],\n",
    "        nlp\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = [preprocessar(batch, nlp) for batch in batched_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vetorizar o corpus\n",
    "def vetorizar_corpus(corpus_preprocessado):\n",
    "    corpus_texto = [' '.join(doc) for doc in corpus_preprocessado]\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        max_df=0.80, \n",
    "        min_df=3,\n",
    "    )\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(corpus_texto)\n",
    "    return tfidf_matrix, tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrices = [vetorizar_corpus(batch) for batch in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 25)\t0.08406705943469693\n",
      "  (0, 0)\t0.07600112418162737\n",
      "  (0, 109)\t0.07600112418162737\n",
      "  (0, 119)\t0.07600112418162737\n",
      "  (0, 22)\t0.09927310685642361\n",
      "  (0, 2)\t0.09109769524814217\n",
      "  (0, 46)\t0.07240642634882266\n",
      "  (0, 29)\t0.07417167292176972\n",
      "  (0, 98)\t0.07600112418162737\n",
      "  (0, 23)\t0.08630317714020486\n",
      "  (0, 114)\t0.0778996274294939\n",
      "  (0, 62)\t0.0778996274294939\n",
      "  (0, 99)\t0.0778996274294939\n",
      "  (0, 118)\t0.0778996274294939\n",
      "  (0, 94)\t0.16083435329418125\n",
      "  (0, 11)\t0.15166278308719405\n",
      "  (0, 51)\t0.15166278308719405\n",
      "  (0, 47)\t0.15166278308719405\n",
      "  (0, 10)\t0.15166278308719405\n",
      "  (0, 111)\t0.17205944802846765\n",
      "  (0, 35)\t0.15166278308719405\n",
      "  (0, 32)\t0.3033255661743881\n",
      "  (0, 3)\t0.15166278308719405\n",
      "  (0, 113)\t0.15166278308719405\n",
      "  (0, 103)\t0.15200224836325474\n",
      "  :\t:\n",
      "  (43, 41)\t0.11123163701910763\n",
      "  (43, 67)\t0.12270126501380434\n",
      "  (43, 61)\t0.2835669256278504\n",
      "  (43, 8)\t0.4449265480764305\n",
      "  (43, 84)\t0.11123163701910763\n",
      "  (43, 50)\t0.11394343037713552\n",
      "  (43, 86)\t0.10861178677821057\n",
      "  (43, 45)\t0.11123163701910763\n",
      "  (43, 20)\t0.11123163701910763\n",
      "  (43, 115)\t0.11967035965036381\n",
      "  (43, 34)\t0.11967035965036381\n",
      "  (43, 105)\t0.11394343037713552\n",
      "  (43, 4)\t0.11394343037713552\n",
      "  (43, 1)\t0.1361749775943446\n",
      "  (43, 95)\t0.11123163701910763\n",
      "  (43, 107)\t0.1325799954137787\n",
      "  (43, 110)\t0.1291448440675046\n",
      "  (43, 42)\t0.10861178677821057\n",
      "  (43, 90)\t0.10861178677821057\n",
      "  (43, 106)\t0.09669930266706046\n",
      "  (43, 63)\t0.11675385575982593\n",
      "  (43, 74)\t0.10861178677821057\n",
      "  (43, 14)\t0.11967035965036381\n",
      "  (43, 37)\t0.11967035965036381\n",
      "  (43, 56)\t0.11967035965036381\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrices[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação das Técnicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar NMF\n",
    "def aplicar_nmf(tfidf_matrix, n_topics):\n",
    "    nmf_model = NMF(n_components=n_topics, random_state=42)\n",
    "    nmf_model.fit(tfidf_matrix)\n",
    "    return nmf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_models = [aplicar_nmf(tfidf_matrix, 3) for tfidf_matrix, _ in tfidf_matrices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NMF(n_components=3, random_state=42),\n",
       " NMF(n_components=3, random_state=42),\n",
       " NMF(n_components=3, random_state=42)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair tópicos\n",
    "def extrair_top_palavras_nmf(nmf_model, tfidf_vectorizer, top_n=10):\n",
    "    palavras = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "    top_palavras = []\n",
    "    for topic in nmf_model.components_:\n",
    "        top_palavras.append([palavras[i] for i in topic.argsort()[-top_n:]])\n",
    "    return top_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_palavras_nmf = [\n",
    "    extrair_top_palavras_nmf(\n",
    "        nmf_models[i],\n",
    "        tfidf_matrices[i][1]\n",
    "        ) \n",
    "    for i in range(len(nmf_models))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['conforme',\n",
       "  'condenado',\n",
       "  'valendo',\n",
       "  'federal',\n",
       "  'acordao',\n",
       "  'recorrente',\n",
       "  'art',\n",
       "  'disposto',\n",
       "  'lei',\n",
       "  'artigo'],\n",
       " ['caput',\n",
       "  'hipotese',\n",
       "  'prevista',\n",
       "  'verificada',\n",
       "  'dano',\n",
       "  'onus',\n",
       "  'sucumbenciais',\n",
       "  'parcial',\n",
       "  'artigo',\n",
       "  'nao'],\n",
       " ['cpc',\n",
       "  'honorarios',\n",
       "  'custas',\n",
       "  'negar',\n",
       "  'legal',\n",
       "  'julgamento',\n",
       "  'ministerio',\n",
       "  'presente',\n",
       "  'fazendaria',\n",
       "  'publico']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_palavras_nmf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular o Coherence Score\n",
    "def calcular_coerencia_nmf(top_palavras, corpus_preprocessado, dictionary):\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=top_palavras,\n",
    "        texts=corpus_preprocessado,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    return coherence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_scores = [\n",
    "    calcular_coerencia_nmf(\n",
    "        top_palavras_nmf[i],\n",
    "        processed_docs[i],\n",
    "        Dictionary(processed_docs[i])\n",
    "    ) \n",
    "    for i in range(len(top_palavras_nmf))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8892691695363256, 0.8632013891759117, 0.9231895296742403]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_topics = [[f\"{' '.join(top_palavras_nmf[i][j])}\" for j in range(3)] for i in range(len(top_palavras_nmf))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_whole = [\n",
    "    {'modelo': nmf_models[i],\n",
    "     'score': nmf_scores[i],\n",
    "     'topicos': nmf_topics[i]} \n",
    "     for i in range(len(nmf_topics))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>score</th>\n",
       "      <th>topicos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NMF(n_components=3, random_state=42)</td>\n",
       "      <td>0.889269</td>\n",
       "      <td>[conforme condenado valendo federal acordao re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NMF(n_components=3, random_state=42)</td>\n",
       "      <td>0.863201</td>\n",
       "      <td>[honorarios custas manter fundamentos proprios...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NMF(n_components=3, random_state=42)</td>\n",
       "      <td>0.923190</td>\n",
       "      <td>[regimento turmas interno tjrj transcricao dis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 modelo     score  \\\n",
       "0  NMF(n_components=3, random_state=42)  0.889269   \n",
       "1  NMF(n_components=3, random_state=42)  0.863201   \n",
       "2  NMF(n_components=3, random_state=42)  0.923190   \n",
       "\n",
       "                                             topicos  \n",
       "0  [conforme condenado valendo federal acordao re...  \n",
       "1  [honorarios custas manter fundamentos proprios...  \n",
       "2  [regimento turmas interno tjrj transcricao dis...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nmf = pd.DataFrame(nmf_whole)\n",
    "df_nmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar LDA\n",
    "def aplicar_lda(tfidf_matrix, n_topics):\n",
    "    \"\"\"\n",
    "    Aplica o modelo LDA em uma matriz TF-IDF.\n",
    "    \"\"\"\n",
    "    lda_model = LDA(n_components=n_topics, random_state=42)\n",
    "    lda_topics = lda_model.fit_transform(tfidf_matrix)\n",
    "    return lda_model, lda_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_models = [aplicar_lda(tfidf_matrix, 3) for tfidf_matrix, _ in tfidf_matrices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LatentDirichletAllocation(n_components=3, random_state=42),\n",
       "  array([[0.04069785, 0.91835711, 0.04094505],\n",
       "         [0.33333333, 0.33333333, 0.33333333],\n",
       "         [0.04385131, 0.91205568, 0.04409302],\n",
       "         [0.33333333, 0.33333333, 0.33333333],\n",
       "         [0.04347648, 0.9123354 , 0.04418812],\n",
       "         [0.53909302, 0.41786813, 0.04303885],\n",
       "         [0.04048864, 0.91853634, 0.04097502],\n",
       "         [0.0483901 , 0.90325712, 0.04835278],\n",
       "         [0.0483901 , 0.90325712, 0.04835278],\n",
       "         [0.09916226, 0.10050819, 0.80032955],\n",
       "         [0.06374425, 0.78178512, 0.15447063],\n",
       "         [0.66482841, 0.16684826, 0.16832333],\n",
       "         [0.53826938, 0.41949684, 0.04223378],\n",
       "         [0.50946163, 0.42204951, 0.06848886],\n",
       "         [0.04348594, 0.91286497, 0.04364909],\n",
       "         [0.05760581, 0.88549541, 0.05689879],\n",
       "         [0.04036234, 0.91907387, 0.0405638 ],\n",
       "         [0.04604119, 0.90264645, 0.05131236],\n",
       "         [0.08403988, 0.84036282, 0.07559731],\n",
       "         [0.07982012, 0.09412431, 0.82605557],\n",
       "         [0.04324041, 0.91327714, 0.04348244],\n",
       "         [0.04953347, 0.90081006, 0.04965646],\n",
       "         [0.06433559, 0.87056866, 0.06509576],\n",
       "         [0.04428432, 0.91118322, 0.04453246],\n",
       "         [0.04385131, 0.91205568, 0.04409302],\n",
       "         [0.04385131, 0.91205568, 0.04409302],\n",
       "         [0.04467145, 0.91046402, 0.04486453],\n",
       "         [0.06036816, 0.81765615, 0.12197569],\n",
       "         [0.044697  , 0.91042393, 0.04487908],\n",
       "         [0.043059  , 0.91365048, 0.04329052],\n",
       "         [0.0409756 , 0.9177992 , 0.0412252 ],\n",
       "         [0.88211966, 0.06318815, 0.05469219],\n",
       "         [0.32822845, 0.62458429, 0.04718726],\n",
       "         [0.31050229, 0.64312902, 0.04636869],\n",
       "         [0.27026   , 0.2826631 , 0.4470769 ],\n",
       "         [0.07591728, 0.87419129, 0.04989144],\n",
       "         [0.11767737, 0.7734193 , 0.10890332],\n",
       "         [0.33333333, 0.33333333, 0.33333333],\n",
       "         [0.33333333, 0.33333333, 0.33333333],\n",
       "         [0.04313541, 0.91300955, 0.04385505],\n",
       "         [0.04385131, 0.91205568, 0.04409302],\n",
       "         [0.0805195 , 0.12505576, 0.79442474],\n",
       "         [0.043059  , 0.91365048, 0.04329052],\n",
       "         [0.04385131, 0.91205568, 0.04409302]])),\n",
       " (LatentDirichletAllocation(n_components=3, random_state=42),\n",
       "  array([[0.08165522, 0.83611556, 0.08222922],\n",
       "         [0.06958302, 0.8602734 , 0.07014358],\n",
       "         [0.91267727, 0.04345947, 0.04386326],\n",
       "         [0.91104171, 0.04426417, 0.04469411],\n",
       "         [0.91112408, 0.04440065, 0.04447527],\n",
       "         [0.86577657, 0.0674755 , 0.06674793],\n",
       "         [0.91409729, 0.0423597 , 0.04354302],\n",
       "         [0.92486433, 0.03732141, 0.03781426],\n",
       "         [0.90572168, 0.04471233, 0.04956599],\n",
       "         [0.08898353, 0.8213902 , 0.08962627],\n",
       "         [0.06872406, 0.8624896 , 0.06878634],\n",
       "         [0.90692459, 0.04569004, 0.04738537],\n",
       "         [0.17918713, 0.65319516, 0.16761771],\n",
       "         [0.91095035, 0.044312  , 0.04473764],\n",
       "         [0.90822913, 0.04586149, 0.04590938],\n",
       "         [0.132509  , 0.64513323, 0.22235777],\n",
       "         [0.90527801, 0.04672659, 0.0479954 ],\n",
       "         [0.91091022, 0.04440733, 0.04468246],\n",
       "         [0.91260557, 0.04355269, 0.04384175],\n",
       "         [0.91526224, 0.04113673, 0.04360104],\n",
       "         [0.91462874, 0.04208394, 0.04328732],\n",
       "         [0.89932383, 0.0493681 , 0.05130807],\n",
       "         [0.11393494, 0.10087065, 0.78519441],\n",
       "         [0.91591306, 0.04191008, 0.04217686],\n",
       "         [0.89508888, 0.04794239, 0.05696872],\n",
       "         [0.91015648, 0.04470108, 0.04514244],\n",
       "         [0.90670093, 0.05165019, 0.04164888],\n",
       "         [0.9014295 , 0.04873365, 0.04983684],\n",
       "         [0.16284147, 0.08924698, 0.74791154],\n",
       "         [0.91252084, 0.04353541, 0.04394374],\n",
       "         [0.91175738, 0.04407773, 0.04416489],\n",
       "         [0.92051878, 0.03942031, 0.04006091],\n",
       "         [0.33333333, 0.33333333, 0.33333333],\n",
       "         [0.91175738, 0.04407773, 0.04416489],\n",
       "         [0.87186289, 0.06282098, 0.06531612],\n",
       "         [0.91175738, 0.04407773, 0.04416489],\n",
       "         [0.91104171, 0.04426417, 0.04469411],\n",
       "         [0.91112408, 0.04440065, 0.04447527],\n",
       "         [0.11605976, 0.09971239, 0.78422785],\n",
       "         [0.91252084, 0.04353541, 0.04394374],\n",
       "         [0.06958302, 0.8602734 , 0.07014358],\n",
       "         [0.09192915, 0.81512152, 0.09294933],\n",
       "         [0.91226019, 0.04335307, 0.04438674],\n",
       "         [0.91500096, 0.04218737, 0.04281166]])),\n",
       " (LatentDirichletAllocation(n_components=3, random_state=42),\n",
       "  array([[0.08403888, 0.08378686, 0.83217427],\n",
       "         [0.08157013, 0.08220102, 0.83622885],\n",
       "         [0.08509457, 0.08583744, 0.82906799],\n",
       "         [0.06455707, 0.87179541, 0.06364752],\n",
       "         [0.04301515, 0.91419581, 0.04278904],\n",
       "         [0.04431601, 0.91162441, 0.04405957],\n",
       "         [0.04376248, 0.91271052, 0.04352699],\n",
       "         [0.29504747, 0.66567037, 0.03928216],\n",
       "         [0.0457421 , 0.90880814, 0.04544976],\n",
       "         [0.3403779 , 0.61340421, 0.04621789],\n",
       "         [0.04749908, 0.90626152, 0.0462394 ],\n",
       "         [0.44598554, 0.48982172, 0.06419274],\n",
       "         [0.364394  , 0.59553353, 0.04007246],\n",
       "         [0.09169147, 0.65117417, 0.25713436],\n",
       "         [0.05054555, 0.90036384, 0.04909061],\n",
       "         [0.72307535, 0.14891005, 0.1280146 ],\n",
       "         [0.14814819, 0.79721872, 0.05463308],\n",
       "         [0.0457421 , 0.90880814, 0.04544976],\n",
       "         [0.06181218, 0.87655493, 0.06163289],\n",
       "         [0.04301515, 0.91419581, 0.04278904],\n",
       "         [0.09187102, 0.09169141, 0.81643758],\n",
       "         [0.11309626, 0.77375815, 0.11314559],\n",
       "         [0.65012206, 0.30595048, 0.04392746],\n",
       "         [0.30718714, 0.29730278, 0.39551008],\n",
       "         [0.04376248, 0.91271052, 0.04352699],\n",
       "         [0.09320573, 0.09451898, 0.81227529],\n",
       "         [0.3444115 , 0.60752265, 0.04806585],\n",
       "         [0.04466166, 0.91081886, 0.04451949],\n",
       "         [0.04466166, 0.91081886, 0.04451949],\n",
       "         [0.07259777, 0.854808  , 0.07259423],\n",
       "         [0.33216428, 0.62768681, 0.04014891],\n",
       "         [0.34388117, 0.61677902, 0.03933982],\n",
       "         [0.04407362, 0.91198186, 0.04394452],\n",
       "         [0.06104468, 0.87783679, 0.06111853],\n",
       "         [0.06060508, 0.879527  , 0.05986792],\n",
       "         [0.06810998, 0.86688735, 0.06500267],\n",
       "         [0.06133552, 0.87765859, 0.06100588],\n",
       "         [0.31522596, 0.64492429, 0.03984975],\n",
       "         [0.51128751, 0.06599896, 0.42271353],\n",
       "         [0.06181218, 0.87655493, 0.06163289],\n",
       "         [0.04466166, 0.91081886, 0.04451949],\n",
       "         [0.04376248, 0.91271052, 0.04352699],\n",
       "         [0.37008136, 0.58937388, 0.04054476],\n",
       "         [0.09187102, 0.09169141, 0.81643758]]))]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_top_palavras_lda(lda_model, tfidf_vectorizer, top_n=10):\n",
    "    \"\"\"\n",
    "    Extrai as top N palavras de cada tópico do modelo LDA.\n",
    "    \"\"\"\n",
    "    palavras = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "    top_palavras = []\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        top_palavras.append([palavras[i] for i in topic.argsort()[-top_n:]])\n",
    "    return top_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_palavras_lda = [extrair_top_palavras_lda(lda_models[i][0], tfidf_matrices[i][1]) for i in range(len(lda_models))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['mantida',\n",
       "  'verificada',\n",
       "  'hipotese',\n",
       "  'prevista',\n",
       "  'caput',\n",
       "  'nao',\n",
       "  'dano',\n",
       "  'onus',\n",
       "  'sucumbenciais',\n",
       "  'parcial'],\n",
       " ['fundamentos',\n",
       "  'proprios',\n",
       "  'recorrente',\n",
       "  'valendo',\n",
       "  'federal',\n",
       "  'acordao',\n",
       "  'disposto',\n",
       "  'art',\n",
       "  'lei',\n",
       "  'artigo'],\n",
       " ['custas',\n",
       "  'cpc',\n",
       "  'negar',\n",
       "  'legal',\n",
       "  'presente',\n",
       "  'ministerio',\n",
       "  'fazendaria',\n",
       "  'julgamento',\n",
       "  'iv',\n",
       "  'publico']]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_palavras_lda[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_coerencia_lda(top_palavras, corpus_preprocessado, dictionary):\n",
    "    \"\"\"\n",
    "    Calcula o Coherence Score para os tópicos gerados pelo LDA.\n",
    "    \"\"\"\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=[[word for word in topic if word in dictionary.token2id] \n",
    "                for topic in top_palavras],\n",
    "        texts=corpus_preprocessado,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    return coherence_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_scores = [\n",
    "    calcular_coerencia_lda(\n",
    "        top_palavras_lda[i],\n",
    "        processed_docs[i],\n",
    "        Dictionary(processed_docs[i])\n",
    "    ) \n",
    "    for i in range(len(top_palavras_lda))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8610600604520294, 0.6840876357921323, 0.882489902729031]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_topics = [[f\"{' '.join(top_palavras_lda[i][j])}\" for j in range(3)] for i in range(len(top_palavras_lda))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_whole = [\n",
    "    {'modelo': lda_models[i],\n",
    "     'score': lda_scores[i],\n",
    "     'topicos': lda_topics[i]} \n",
    "     for i in range(len(lda_topics))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>score</th>\n",
       "      <th>topicos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(LatentDirichletAllocation(n_components=3, ran...</td>\n",
       "      <td>0.861060</td>\n",
       "      <td>[mantida verificada hipotese prevista caput na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(LatentDirichletAllocation(n_components=3, ran...</td>\n",
       "      <td>0.684088</td>\n",
       "      <td>[fundamentos recorrente principios sendo feder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(LatentDirichletAllocation(n_components=3, ran...</td>\n",
       "      <td>0.882490</td>\n",
       "      <td>[instancia oficial janeiro rio capital outubro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              modelo     score  \\\n",
       "0  (LatentDirichletAllocation(n_components=3, ran...  0.861060   \n",
       "1  (LatentDirichletAllocation(n_components=3, ran...  0.684088   \n",
       "2  (LatentDirichletAllocation(n_components=3, ran...  0.882490   \n",
       "\n",
       "                                             topicos  \n",
       "0  [mantida verificada hipotese prevista caput na...  \n",
       "1  [fundamentos recorrente principios sendo feder...  \n",
       "2  [instancia oficial janeiro rio capital outubro...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lda = pd.DataFrame(lda_whole)\n",
    "df_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar LSA\n",
    "def aplicar_lsa(tfidf_matrix, n_topics):\n",
    "    \"\"\"\n",
    "    Aplica o modelo LSA em uma matriz TF-IDF.\n",
    "    \"\"\"\n",
    "    lsa_model = TruncatedSVD(n_components=n_topics, random_state=42)\n",
    "    lsa_model.fit(tfidf_matrix)\n",
    "    return lsa_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_models = [aplicar_lsa(tfidf_matrix, 3) for tfidf_matrix, _ in tfidf_matrices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TruncatedSVD(n_components=3, random_state=42),\n",
       " TruncatedSVD(n_components=3, random_state=42),\n",
       " TruncatedSVD(n_components=3, random_state=42)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Extrair tópicos\n",
    "def extrair_top_palavras_lsa(lsa_model, tfidf_vectorizer, top_n=10):\n",
    "    \"\"\"\n",
    "    Extrai as top N palavras de cada tópico do modelo LSA.\n",
    "    \"\"\"\n",
    "    palavras = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "    top_palavras = []\n",
    "    for topic in lsa_model.components_:\n",
    "        top_palavras.append([palavras[i] for i in topic.argsort()[-top_n:]])\n",
    "    return top_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_palavras_lsa = [extrair_top_palavras_lsa(lsa_models[i], tfidf_matrices[i][1]) for i in range(len(lsa_models))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['fundamentos',\n",
       "  'resolucao',\n",
       "  'valendo',\n",
       "  'recorrente',\n",
       "  'acordao',\n",
       "  'federal',\n",
       "  'art',\n",
       "  'disposto',\n",
       "  'lei',\n",
       "  'artigo'],\n",
       " ['caput',\n",
       "  'verificada',\n",
       "  'prevista',\n",
       "  'mantida',\n",
       "  'parcial',\n",
       "  'sucumbenciais',\n",
       "  'onus',\n",
       "  'dano',\n",
       "  'nao',\n",
       "  'artigo'],\n",
       " ['iv',\n",
       "  'negar',\n",
       "  'legal',\n",
       "  'parcial',\n",
       "  'nao',\n",
       "  'presente',\n",
       "  'ministerio',\n",
       "  'fazendaria',\n",
       "  'julgamento',\n",
       "  'publico']]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_palavras_lsa[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular o Coherence Score\n",
    "def calcular_coerencia_lsa(top_palavras, corpus_preprocessado, dictionary):\n",
    "    \"\"\"\n",
    "    Calcula o Coherence Score para os tópicos gerados pelo LSA.\n",
    "    \"\"\"\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=[[word for word in topic if word in dictionary.token2id] \n",
    "                for topic in top_palavras],\n",
    "        texts=corpus_preprocessado,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    return coherence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_scores = [calcular_coerencia_lsa(top_palavras_lsa[i], processed_docs[i], Dictionary(processed_docs[i])) for i in range(len(top_palavras_lsa))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7664024517729856, 0.9037100442133043, 0.9267319723514312]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_topics = [[f\"{' '.join(top_palavras_lsa[i][j])}\" for j in range(3)] for i in range(len(top_palavras_lsa))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_whole = [{'modelo': lsa_models[i], 'score': lsa_scores[i], 'topicos': lsa_topics[i]} for i in range(len(lsa_topics))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>score</th>\n",
       "      <th>topicos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TruncatedSVD(n_components=3, random_state=42)</td>\n",
       "      <td>0.766402</td>\n",
       "      <td>[fundamentos resolucao valendo recorrente acor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TruncatedSVD(n_components=3, random_state=42)</td>\n",
       "      <td>0.903710</td>\n",
       "      <td>[resolucao principios sendo recorrente federal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TruncatedSVD(n_components=3, random_state=42)</td>\n",
       "      <td>0.926732</td>\n",
       "      <td>[valendo federal condenado honorarios custas r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          modelo     score  \\\n",
       "0  TruncatedSVD(n_components=3, random_state=42)  0.766402   \n",
       "1  TruncatedSVD(n_components=3, random_state=42)  0.903710   \n",
       "2  TruncatedSVD(n_components=3, random_state=42)  0.926732   \n",
       "\n",
       "                                             topicos  \n",
       "0  [fundamentos resolucao valendo recorrente acor...  \n",
       "1  [resolucao principios sendo recorrente federal...  \n",
       "2  [valendo federal condenado honorarios custas r...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lsa = pd.DataFrame(lsa_whole)\n",
    "df_lsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise da Coerência dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = {'nmf': df_nmf, 'lda': df_lda, 'lsa': df_lsa}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for modelo_tipo, df in resultados.items():\n",
    "    df['modelo_tipo'] = modelo_tipo\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenar todos os dataframes\n",
    "df_resultados = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Coesão dos Grupos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise de Coesão dos Grupo -> kmeans.clusters fit(x) {Coesão} -> kmeans.Inertia [evitar negativos] {Distinção} -> kmeans.silluette_score {Relação entre Coesão e Distinção} [coeficiente hand - eval]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falsos Positivos e Negativos de Cada Tópico -> Justificativa -> Passa por LSA (Importancia Semantica) | pLSA (Probabilistica Importancia Semantica) ->  modelo exato [MUITO IMPORTANTE] | cluster abrangente [POUCO IMPORTANTE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibragem de Modelo -> \"Aleatório\" -> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topic-modeling-paper-aq0E2InM-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
